% include the figures path relative to the master file
\graphicspath{ {./content/method/figures/} }

\section{Experimental Setup}\label{sec:exp}

The experimental set-up is summarized in table~\ref{tab:survey-tab}.
Where the most relevant works in Sect.\,\ref{sec:review} are formulated as the as the 5-steps standard classification procedure described in Fig.\,\ref{fig:ML-scheme}.

\input{content/method/Survey-Table.tex}

\subsection{Implementation details}\label{sec:exp:implementation}
For reproductivity purposes, the experimentation described in this work can be found in \cite{rethinopaty20016apr-repoICPR},
where the image processing and \gls{ml} rapid pipeline prototyping library \emph{Protoclass}~\cite{protoclass2016apr-repoICPR} has been used to implement the methodologies in Tab.\,\ref{tab:survey-tab} in accordance to proposed experimentation framework.
Each methodology implementation can be seen as a plug-in to experiment in \cite{rethinopaty20016apr-repoICPR}, while references to stand-alone implementation of these methodologies can be found in Tab.\,\ref{tab:survey-tab}.
All the repositories are publicly available and provided with tests to ensure that our implementation agrees with the results reported by the original works.

Notice that Liu~\emph{et~al.} train the algorithm at the B-scan level, and \gls{seri} dataset provides \gls{gt} at volume level only.
Thus, we replicated here the training strategy reported by Srinivasan~\emph{et~al.} which considers to be abnormal all the B-scans from any abnormal volume~\cite{Srinivasan2014}.
From the methods reviewed in Sect.\,\ref{sec:review}, we decline to implement Albarrak~\emph{et~al.} and Anantrasirichai~\textit{et~al.}.
The former does not provide sufficient implementation details to replicate their results~\cite{albarrak2013age}.
While, the latter, requires of a layer segmentation stage using a generic segmentation algorithm and further user validation~\cite{anantrasirichai2013svm}.


\subsection{Evaluation}\label{sec:exp:evaluation}
All the experiments are evaluated in terms of \gls{se} and \gls{sp} (see Eq.\,\ref{eq:sesp}) using the \gls{lopocv} strategy, in line with \cite{Lemaintre2015miccaiOCT}.
The \gls{se} evaluates the performance of the classifier with respect to the positive class, while the \gls{sp} evaluates its performance with respect to negative class.

\begin{align}
 \gls{se}  = \frac{TP}{TP+FN} \qquad \gls{sp} = \frac{TN}{TN+FP}
 \label{eq:sesp}
\end{align}

The use of \gls{lopocv} implies that at each round, a pair \gls{dme}-normal volume is selected for testing while the remaining volumes are used for training.
Subsequently, no \gls{se} or \gls{sp} variance can be reported.
However, \gls{lopocv} strategy has been adopted despite this limitation due to the reduced size of the dataset.

% \subsection{Management of data depending terms}
% \deleted[id=sik]{
%   Be aware that when computing the GMM~\cite{repo_des}, or the dictionary
%   \cite{repo_lem}, only the training data for the current fold is used.
%   Therefore such modules are recomputed at each fold.
% }
% \deleted[id=sik]{
%   Other parameter tuning such the case of XXXX and YYYYY are also carried out using only ZZZZ
% }
