include the figures path relative to the master file
\graphicspath{ {./content/survey/figures/} }

\section{Related Work}\label{sec:rw}
This section reviews the works straightly addressing the problem of classifying \oct volumes as normal or abnormal. A summary can be found in Table~\ref{tab:survey-tab}.
%This section reviews, up to our knowledge, the works straightly addressing the problem of classifying \oct volume as normal or abnormal. A summary can be found in \Cref{tab:survey}.

Srinivasan\,\textit{et al.}~\cite{Srinivasan2014} proposed a classification method to distinguish \gls{dme}, \gls{amd} and normal \gls{sdoct} volumes.
%The authors in~\cite{Srinivasan2014} proposed a classification method for the detection of \gls{dme} versus \gls{amd} and normal \gls{oct} images.
The \gls{oct} images are pre-processed by reducing the speckle noise by enhancing the sparsity in a transform-domain and flattening the retinal curvature to reduce the inter-patient variations.
%The method is based on pre-processing to reduce the speckle noise in \gls{oct} images and flattening of the images to reduce the variation of retinal curvature among patients.
Then, \gls{hog} are extracted for each slice of a volume and a linear \gls{svm} is used for classification.
On a dataset of 45 patients equally subdivided into the three aforementioned classes, this method leads to a correct classification rate of $100 \%$, $100 \%$ and $86.67 \%$ for normal, \gls{dme} and \gls{amd} patients, respectively.
%On a dataset of 45 patients containing 15 normal subjects, 15 \gls{dme} patients and 15 \gls{amd} patients, the methods achieved a correct classification of $100 \%$, $100 \%$ and $86.67 \%$ for \gls{amd}, \gls{dme} and normal cases respectively.

Venhuizen\,\textit{et al.} proposed a method for \gls{oct} images classification using the \gls{bow} models~\cite{Venhuizen2015}.
The method starts with the detection and selection of keypoints in each individual B-scan, by keeping the most salient points corresponding to the top $3 \%$ of the vertical gradient values. Then, a texton of size $9 \times 9$ pixels is extracted around each keypoint, and \gls{pca} is applied to reduce the dimension of every texton to get a feature vector of size $9$.
All extracted feature vectors are used to create a codebook using \textit{k}-means clustering.
Then, each \gls{oct} volume is represented in terms of this codebook and is characterized as a histogram that captures the codebook occurrences.
These histograms are used as feature vector to train a \gls{rf} with a maximum of $100$ trees.
The method was used to classify \gls{oct} volumes between \gls{amd} and normal cases and achieved an \gls{auc} of $0.984$ with a dataset of $384$ \gls{oct} volumes.

Liu\,\textit{et al.} proposed a methodology for detecting macular pathology in \gls{oct} images using \gls{lbp} and gradient information as attributes~\cite{Liu2011}.
The method starts by aligning and flattening the images and creating a $3$-level multi-scale spatial pyramid.
The edge and \gls{lbp} histograms are then extracted from each block of every level of the pyramid.
%is created and edge and \gls{lbp} histograms are extracted in each block at every level of the pyramid.
All the obtained histograms are concatenated into a global descriptor whose dimensions are reduced using \gls{pca}.
Finally a \gls{svm} with an \gls{rbf} kernel is used as classifier.
The method achieved good results in detection \gls{oct} scan containing different pathology such as \gls{dme} or \gls{amd}, with an \gls{auc} of $0.93$ using a dataset of $326$ \gls{oct} scans.

% Our later study proposes a standard classification procedure to differentiate between \gls{dme} and normal \gls{sdoct} volumes~\cite{Lemaitre2015}The data is pre-processed using \gls{nlm} filtering.
% The volumes are mapped into discrete set of structures namely: local, when these structures correspond to patches; or global, when the structures correspond to volume slices or the whole volume.
% These structures are described in terms of texture using \gls{lbp} or \gls{lbptop} and encoded using histogram, \gls{pca} or \gls{bow} to produce a single feature vector in order to present the volumes to a \gls{rf} classifeir.
% This methodology was tested against Venhuizen\,\textit{et al.}~\cite{Venhuizen2015} using public and non-public datasets showing an improvement within the results achieving a \gls{se} of 87.5\% and a \gls{sp} of 75\%.
% The obtained results of this study is listed in Sect.\,\ref{sec:exp}.

%As stated in previous section, this research is a continue of our previous work, where we intend to evaluate the influence of different pre-processing, \gls{bow} representation and various classifiers.
%Our proposed pipeline with detail description of each step is presented in the following section.
As stated in the previous section, our current research is an extension of our previous work~\cite{Lemaitre2015} with further contributions and evaluations at every stages of our classification framework.

%\DTLloaddb[keys={task,Srinivasan,Venhuizen,Liu,Lemaitre}]
%          {survey}{./content/survey/tables/survey.csv}
%\begin{table}
%  \caption{Other methodologies overview}
%  \centering
%  \input{./content/survey/tables/survey.tex}
%  \label{tab:survey}
%\end{table}


\input{content/survey/Survey-Table.tex}
