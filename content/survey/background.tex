% include the figures path relative to the master file
\graphicspath{ {./content/method/figures/} }
\section{Background}\label{sec:review}
This section reviews works straightly addressing the problem of classifying \gls{oct} volumes as normal or abnormal, regardless of the target pathology.
The methods are categorized in terms of its learning strategy, namely: supervised or semi-supervised.


\subsection{Supervised methods}
% Common framework
% \added[id=mojh]{
%   All the previously mentioned methods follow a similar pipeline or framework, which consists of different steps.
%   We categorized these steps as pre-processing, feature extraction, mapping, feature representation and finally classification, as it is shown in Fig.\,\ref{fig:ML-scheme}.

%   Pre-processing of \gls{oct} volumes, as noted in Sect.\,\ref{sec:review}, consists of denoising, flattening the retinal curvature, aligning the B-scans through the whole volume and finally cropping or resizing the volumes.
%   Feature extraction refers to extraction of different textural and shape information from the B-scan or the volumes.
%   Mapping step is used to determine a discrete set of elements (structures) representing a sample (i.e.B-scan/volume).
%   In this step either one structure is used per sample namely global-mapping or the features are extracted with reference to a set of structures, i.e.dense or sparse patches through the sample, local-mapping.

%   In feature representation step, the representation of the final descriptor prior to classification is decided.
%   The extracted features using different mapping techniques can be represented in lower dimensions (using \gls{pca} for instance), as a concatenated of descriptor, histogram of words (using \gls{bow}) or sparse representation (sparse coding).
% }

Supervised classification is based on full annotated and labeled training set.
In such methods the labeled training data is used to train the classifier function and the learned function is then used for prediction.
% Semi-supervised classification takes advantage of both unlabeled and labeled data.
% This techniques are particularly useful when there is lack of annotated data moreover it has shown that use of small amount of labeled data in conjunction of unlabeled data can increase the learning accuracy.
%
Figure~\ref{fig:ML-scheme} describes a prevalent structure for supervised classification.
The volumes undergo:
(i) \emph{Pre-processing} to reduce the natural noise of the images and correct acquisition deficiencies;
(ii) \emph{Feature detection} to quantify visual cues like appearance, texture, shape, etc.
(iii) \emph{Mapping} to determine the discrete set of elements (structures) to represent the sample to be classified (i.e.B-scan/volume);
(iv) \emph{Feature extraction} to associate a descriptor for each element from the \emph{mapping-stage} based on the \emph{detected features};
(v) \emph{Classification}.

% The details implementation of the following methods and their integration to our common framework is described in Sect.~\textit{experiments}.

\begin{figure*}
  \centering{
  \includegraphics[width=1\linewidth]{ml-2}}
  \caption{Common framework}
  \label{fig:ML-scheme}
\end{figure*}

%%% Venhuizen2015
%
% Brief method description (or goal)
Venhuizen\,\textit{et al.} proposed a method classification method to distinguish between \gls{amd} and normal \gls{sdoct} volumes using \gls{bow} models~\cite{Venhuizen2015}.
%
% Method description
The method detects and selects a set of keypoints at each individual B-scan.
Essentially, keeping the salient points comprised at the top $3\%$ of the vertical gradient values.
Then, a texton of size $9 \times 9$ pixels is extracted around each keypoint, and \gls{pca} is applied to reduce the dimension of every texton to get a feature vector of size $9$.
All extracted feature vectors are used to create a codebook using \textit{k}-means clustering.
Then, each \gls{oct} volume is represented in terms of this codebook and is characterized as a histogram that captures the codebook occurrences.
These histograms are used as feature vector to train a \gls{rf} with a maximum of $100$ trees.
%
% Reported results
The method is tested using a publicly available dataset of $384$ \gls{oct} volumes~\cite{VENHUIZEN_DATASET}, achieving an \gls{auc} of $0.984$.

%%% Venhuizen2015
%
% Brief method description (or goal)
Srinivasan\,\textit{et~al.}~\cite{Srinivasan2014} proposed a classification method to distinguish \gls{dme}, \gls{amd} and normal \gls{sdoct} volumes.
%
% Method description
The \gls{oct} images pre-processed by first enhancing sparsity in a transform-domain (BM3D~\cite{dabov2007image}), to reduce their speckle noise, and then by flattening the retinal curvature to reduce the inter-patient variations.
\gls{hog} features are then extracted from multi-resolution pyramid of each pre-processed slice of a volume.
These features are classified using a linear \gls{svm}.
Note that the method classifies each individual B-scan into one of three categories, i.e.\gls{dme}, \gls{amd}, and normal, and then classifies a volume based on the number of B-scans in each category.
%
% Reported results
The method is also tested using a publicly available of $45$ patients equally subdivided into the three aforementioned classes, this method leads to a correct classification rate of $100 \%$, $100 \%$ and $86.67 \%$ for normal, \gls{dme} and \gls{amd} patients, respectively.
\todo{is this the TP?}
% The images that have been used in their paper, are publicly available but are already preprocessed (i.e., denoised), have different sizes for the \gls{oct} volumes, do not offer a huge variability in term of \gls{dme} lesions, and some of them, without specifying which, have been excluded for the training phase; all these reasons prevent us from using this dataset to benchmark our work.

Replicating the method proposed by Srinivasan \textit{et~al.}~\cite{Srinivasan2014} and adding \gls{pca} to the feature extraction step, as was proposed by Venhuizen \textit{et al.}~\cite{Venhuizen2015}, we also compare the performance of extracted \gls{hog} and \gls{lbp} features (similar to \cite{Srinivasan2014}, features are extracted from multi-resolution pyramid) for classification of B-scans, and accordingly volumes.
{\color{red}This work was submitted for publication to a recent conference.}

Lemaitre~\emph{et~al.}~\cite{Lemaintre2015miccaiOCT} propose a metho based on \gls{lbp} features to describe the texture of \gls{oct} images and dictionary learning using the \gls{bow} models~\cite{Sivic2003}.
Note that using \gls{bow} and dictionary learning contrary to \cite{Srinivasan2014} the classification is performed per volume, rather than B-scan.
In this method the \gls{oct} images are first pre-processed using \gls{nlm} filtering, to reduce the speckle noise.
%The data is pre-processed using \gls{nlm} filtering.
Then the volumes are mapped into discrete set of structures namely: local, when these structures correspond to patches; or global, when they correspond to volume slices or the whole volume.
According to different mapping, \gls{lbp} or \gls{lbptop} texture features are extracted and represented (per volume) using histogram, \gls{pca} or \gls{bow}.
The final feature descriptors per volumes are classified using \gls{rf} classifier.
This methodology was tested against Venhuizen\,\textit{et al.}~\cite{Venhuizen2015} using public and non-public datasets showing an improvement within the results achieving a \gls{se} of 87.5\% and a \gls{sp} of 75\%.

%
% description
Liu\,\textit{et al.} proposed a methodology aiming for B-scan classification, rather than volume classification.
The classification goal is to distinguish between macular pathology and normal \gls{oct} B-scan images using \gls{lbp} and gradient information as attributes~\cite{Liu2011}.
%
% Method description
The method starts by aligning and flattening the images and creating a $3$-level multi-scale spatial pyramid.
The edge and \gls{lbp} histograms are then extracted from each block of every level of the pyramid.
%is created and edge and \gls{lbp} histograms are extracted in each block at every level of the pyramid.
All the obtained histograms are concatenated into a global descriptor whose dimensions are reduced using \gls{pca}.
Finally a \gls{svm} with an \gls{rbf} kernel is used as classifier.
%
% results report
The method achieved good results in detection \gls{oct} scan containing different pathology such as \gls{dme} or \gls{amd}, with an \gls{auc} of $0.93$ using a dataset of $326$ \gls{oct} scans.

\subsection{Semi-supervised methods}
An example of semi-supervised approach for \gls{sdoct} classification is recently proposed by Sankar. \textit{et al.}~\cite{sankar2016classification}.
The proposed method is based on appearance modeling of normal \gls{oct} images using \gls{gmm} and anomaly detection.
The abnormal B-scans are detected as outliers to the fitted \gls{gmm} and volume classification is performed based on the number of detected outliers in the volume.

%The proposed method is based on modeling the appearance of the normal \gls{oct} images using a \gls{gmm} and detecting abnormal \gls{oct} images as outliers.
%Use an anomaly detection approach to identify abnormal B-scan as outliers to the \gls{gmm} and finally detect unhealthy \gls{oct} volumes based on the number of abnormal B-scan.
This approach differs from supervised approaches since the B-scan detection method does not require a labeled training set of B-scans.
This method starts by pre-processing the B-scans using resizing, flattening and denoising (\gls{nlm} filter).
The features are extracted by taking the intensity information of each B-scan and applying \gls{pca} to reduce their dimension.
The feature space is then modeled using \gls{gmm}.
In the testing stage, for the new B-scan, the features are extracted in a similar way and they are classified as normal or abnormal based on their Mahalanobis distance to the \gls{gmm}.
Finally the volume classification is performed considering the umber of outliers (abnormal) B-scans per volume.

% \input{content/survey/Survey-Table.tex}
