% include the figures path relative to the master file
\graphicspath{ {./content/method/figures/} }
\section{Background}\label{sec:review}
This section reviews works straightly addressing the problem of classifying \gls{oct} volumes as normal or abnormal, regardless of the targeted pathology.
The methods are categorized in terms of their learning strategy, namely supervised or semi-supervised learning.


\subsection{Supervised methods}
% Common framework
% \added[id=mojh]{
%   All the previously mentioned methods follow a similar pipeline or framework, which consists of different steps.
%   We categorized these steps as pre-processing, feature extraction, mapping, feature representation and finally classification, as it is shown in Fig.\,\ref{fig:ML-scheme}.

%   Pre-processing of \gls{oct} volumes, as noted in Sect.~\ref{sec:review}, consists of denoising, flattening the retinal curvature, aligning the B-scans through the whole volume and finally cropping or resizing the volumes.
%   Feature extraction refers to extraction of different textural and shape information from the B-scan or the volumes.
%   Mapping step is used to determine a discrete set of elements (structures) representing a sample (i.e.B-scan/volume).
%   In this step either one structure is used per sample namely global-mapping or the features are extracted with reference to a set of structures, i.e.dense or sparse patches through the sample, local-mapping.

%   In feature representation step, the representation of the final descriptor prior to classification is decided.
%   The extracted features using different mapping techniques can be represented in lower dimensions (using \gls{pca} for instance), as a concatenated of descriptor, histogram of words (using \gls{bow}) or sparse representation (sparse coding).
% }

Supervised learning is based on a fully annotated and labeled training set.
In this approach, the labeled training data are used to train the classifier function later used for prediction.
% Semi-supervised classification takes advantage of both unlabeled and labeled data.
% This techniques are particularly useful when there is lack of annotated data moreover it has shown that use of small amount of labeled data in conjunction of unlabeled data can increase the learning accuracy.
%
Figure~\ref{fig:ML-scheme} illustrates a prevalent framework for supervised learning.
Each \gls{sdoct} volume undergoes:
(i)~\emph{pre-processing} to reduce noise and other acquisition deficiencies which alter the images;
(ii)~\emph{feature detection} to quantify visual cues like appearance, texture, shape, etc.;
(iii)~\emph{mapping} in which a sample is either considered as whole (i.e., global) or partitioned into a set of sub-elements (i.e., local dense/sparse patches, pyramid, etc.);
(iv)~\emph{feature representation} to associate a descriptor (e.g., concatenation, statistics, histogram, \gls{pca}, \gls{bow}, etc.) for each element from the \emph{mapping-stage}.
This descriptor packages the visual cues related to the sample;
(v)~\emph{classification} to determine the associated class of each sample.

% The details implementation of the following methods and their integration to our common framework is described in Sect.~\textit{experiments}.

\begin{figure*}
  \centering{
  \includegraphics[width=1\linewidth]{ml-2}}
  \caption{Common framework}
  \label{fig:ML-scheme}
\end{figure*}

%%% Venhuizen2015
%
% Brief method description (or goal)
Venhuizen~\textit{et~al.} propose a classification method to distinguish between \gls{amd} and normal \gls{sdoct} volumes using \gls{bow} models~\cite{Venhuizen2015}.
%
% Method description
A set of keypoints are detected and selected at each individual B-scan, by keeping the salient points included in the top $3 \%$ of the vertical gradient values.
Around each of these keypoints, a \SI[product-units=repeat]{9x9}{\px} texton is extracted, generating a feature vector of $81$ dimensions, later reduce to $9$ using \gls{pca}.
All extracted feature vectors are used to create a codebook using \textit{k}-means clustering.
Then, each \gls{oct} volume descriptor is represented as a histogram that captures the codebook occurrences and are classified by a \gls{rf} composed of $100$ trees.
%
% Reported results
The method is tested using a publicly available dataset of $384$ \gls{oct} volumes~\cite{farsiu2014quantitative}, achieving an \gls{auc} of $0.984$.

%%% Srinivasan2014
%
% Brief method description (or goal)
Srinivasan~\textit{et~al.} propose a classification method to distinguish \gls{dme}, \gls{amd}, and normal \gls{sdoct} volumes~\cite{Srinivasan2014}.
%
% Method description
Each \gls{oct} slice is pre-processed using \gls{bm3d} to reduce the speckle noise and is flattened to reduce the inter-patient retinal curvature variations.
A multi-resolution pyramid is generated for each pre-processed slice and a \gls{hog} feature is computed for each layer.
These features are classified using a linear \gls{svm}.
Note that each individual B-scan is classified into one of the three categories, namely \gls{dme}, \gls{amd}, and normal, and a volume is label to a given class by taking the majority vote of all B-scans.
%
% Reported results
This method is also tested using a publicly available dataset, composed of $45$ patients equally subdivided into the three targeted classes.
Correct classification rates of $100 \%$, $100 \%$ and $86.67 \%$ are obtained for normal, \gls{dme}, and \gls{amd} patients, respectively.
% The images that have been used in their paper, are publicly available but are already preprocessed (i.e., denoised), have different sizes for the \gls{oct} volumes, do not offer a huge variability in term of \gls{dme} lesions, and some of them, without specifying which, have been excluded for the training phase; all these reasons prevent us from using this dataset to benchmark our work.

Extending the previous work, Alsaih~\emph{et~al.}~\cite{Alsaih2016apr-repoICPR} aggregate \gls{lbp} to \gls{hog} in order to add texture information and reduce the number of dimension using \gls{pca}, similarly to Venhuizen~\textit{et~al.}.

Lema\^itre~\emph{et~al.} propose a method based on \gls{lbp} features to describe the texture of \gls{oct} images and dictionary learning using the \gls{bow} models~\cite{Lemaintre2015miccaiOCT}.
%Note that using \gls{bow} and dictionary learning contrary to \cite{Srinivasan2014} the classification is performed per volume, rather than B-scan.
In this method, the \gls{oct} images are first pre-processed using \gls{nlm} filtering, to reduce the speckle noise.
%The data is pre-processed using \gls{nlm} filtering.
Then, the volumes are mapped into a discrete set of structures: (i) local corresponding to patches, or (ii) global corresponding to volume slices or the whole volume.
According to the chosen mapping, \gls{lbp} or \gls{lbptop} texture features are extracted and represent each volume through histogram, \gls{pca}, or \gls{bow} representation.
The final feature descriptors are classified using \gls{rf} classifier.
This methodology is tested against Venhuizen~\textit{et~al.}~\cite{Venhuizen2015} using public and non-public datasets showing an improvement within the results by achieving a \gls{se} of $87.5 \%$ and a \gls{sp} of $75 \%$.

%
% description
Liu~\textit{et~al.} propose a methodology aiming at classifying B-scan rather than volume.
The classification goal is to distinguish between macular pathology and normal \gls{oct} B-scan images using \gls{lbp} and gradient information as attributes~\cite{Liu2011}.
%
% Method description
Each \gls{oct} slice are flattened before to create a $3$-level mutlti-scale spatial pyramid.
From each layer of this pyramid, edges are extracted and \gls{lbp} descriptors are computed for the flattened slice and the edge map.
%is created and edge and \gls{lbp} histograms are extracted in each block at every level of the pyramid.
All the obtained histograms are concatenated into a global descriptor whose dimensions are reduced using \gls{pca}.
Finally, a \gls{svm} with an \gls{rbf} kernel is used as classifier.
%
% results report
A detection rate with an \gls{auc} of $0.93$ is achieved, using a dataset of $326$ \gls{oct} scans with various pathologies.

%Albarrak paper
% description
Albarrak~\textit{et~al.} propose another classification framework to differentiate \gls{amd} and normal volumes~\cite{albarrak2013age}.
%
% Method description
Each \gls{oct} slice undergoes two pre-processing routines: (i) a joint denoising and cropping step using the split Bregman isotropic total variation algorithm and (ii) a flattening step by fitting a second-order polynomial using a least-square approach.
Then, \gls{lbptop} and \gls{hog} combined with \gls{lbptop} features are extracted from individual sub-volumes from each original cropped volume.
These features are concatenated into a single feature vector per \gls{oct} volume and its dimension is reduced using \gls{pca}.
Finally, a Bayesian network classifier is used to classify the volumes.
%
%results
The classification performance of the framework in terms of \gls{se} and \gls{sp} achieve $92.4 \%$ and $90.5 \%$, respectively, outperforming the method of Liu~\emph{et~al.}~\cite{Liu2011}, using a dataset composed of $140$ \gls{oct} volumes.

% Anantrairichai paper
% description
Anantrasirichai~\textit{et~al.} propose to detect glaucoma in \gls{oct} images based on a variety of texture descriptor~\cite{anantrasirichai2013svm}.
%
%Method description
The texture information is described through \gls{lbp}, \gls{glcm}, wavelet, granulometry, run length measures, and intensity level distributions in combination with retinal layer thickness estimation, without any pre-processing.
Each feature vector is projected using \gls{pca} before to be classified using an \gls{svm} with both linear and \gls{rbf} kernel.
%
% results
The best performance is obtained by combining the layer thickness information with the texture descriptors to get an \gls{acc} of $81.95 \%$.

\subsection{Semi-supervised methods}
An example of semi-supervised approach for \gls{sdoct} classification is recently proposed by Sankar~\textit{et~al.}~\cite{sankar2016classification}.
The proposed method is based on appearance modeling of normal \gls{oct} images using \gls{gmm} and anomaly detection.
The abnormal B-scans are detected as outliers to the fitted \gls{gmm} and volume classification is performed based on the number of detected outliers in the volume.

%The proposed method is based on modeling the appearance of the normal \gls{oct} images using a \gls{gmm} and detecting abnormal \gls{oct} images as outliers.
%Use an anomaly detection approach to identify abnormal B-scan as outliers to the \gls{gmm} and finally detect unhealthy \gls{oct} volumes based on the number of abnormal B-scan.
This approach differs from supervised approaches since the B-scan detection method does not require a labeled training set of B-scans.
This method starts by pre-processing the B-scans using resizing, flattening and denoising (\gls{nlm} filter).
The features are extracted by taking the intensity information of each B-scan and applying \gls{pca} to reduce their dimension.
The feature space is then modeled using \gls{gmm}.
In the testing stage, for the new B-scan, the features are extracted in a similar way and they are classified as normal or abnormal based on their Mahalanobis distance to the \gls{gmm}.
Finally the volume classification is performed considering the umber of outliers (abnormal) B-scans per volume.

% \input{content/survey/Survey-Table.tex}
