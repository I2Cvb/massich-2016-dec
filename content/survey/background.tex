% include the figures path relative to the master file
\graphicspath{ {./content/method/figures/} }
\section{Background}\label{sec:review}
This section reviews works straightly addressing the problem of classifying \gls{oct} volumes as normal or abnormal, regardless of the target pathology.
The methods are categorized in terms of its learning strategy, namely: supervised or semi-supervised.


\subsection{Supervised methods}
% Common framework
% \added[id=mojh]{
%   All the previously mentioned methods follow a similar pipeline or framework, which consists of different steps.
%   We categorized these steps as pre-processing, feature extraction, mapping, feature representation and finally classification, as it is shown in Fig.\,\ref{fig:ML-scheme}.

%   Pre-processing of \gls{oct} volumes, as noted in Sect.\,\ref{sec:review}, consists of denoising, flattening the retinal curvature, aligning the B-scans through the whole volume and finally cropping or resizing the volumes.
%   Feature extraction refers to extraction of different textural and shape information from the B-scan or the volumes.
%   Mapping step is used to determine a discrete set of elements (structures) representing a sample (i.e.B-scan/volume).
%   In this step either one structure is used per sample namely global-mapping or the features are extracted with reference to a set of structures, i.e.dense or sparse patches through the sample, local-mapping.

%   In feature representation step, the representation of the final descriptor prior to classification is decided.
%   The extracted features using different mapping techniques can be represented in lower dimensions (using \gls{pca} for instance), as a concatenated of descriptor, histogram of words (using \gls{bow}) or sparse representation (sparse coding).
% }

Supervised classification is based on full annotated and labeled training set.
In such methods the labeled training data is used to train the classifier function and the learned function is then used for prediction.
% Semi-supervised classification takes advantage of both unlabeled and labeled data.
% This techniques are particularly useful when there is lack of annotated data moreover it has shown that use of small amount of labeled data in conjunction of unlabeled data can increase the learning accuracy.
%
Figure~\ref{fig:ML-scheme} describes a prevalent structure for supervised classification.
The volumes undergo:
(i) \emph{Pre-processing} to reduce the natural noise of the images and correct acquisition deficiencies;
(ii) \emph{Feature detection} to quantify visual cues like appearance, texture, shape, etc.
(iii) \emph{Mapping} to determine the discrete set of elements (structures) to represent the sample to be classified (i.e.B-scan/volume);
(iv) \emph{Feature extraction} to associate a descriptor for each element from the \emph{mapping-stage} based on the \emph{detected features};
(v) \emph{Classification}.

% The details implementation of the following methods and their integration to our common framework is described in Sect.~\textit{experiments}.

\begin{figure*}
  \centering{
  \includegraphics[width=1\linewidth]{ml-2}}
  \caption{Common framework}
  \label{fig:ML-scheme}
\end{figure*}

%%% Venhuizen2015
%
% Brief method description (or goal)
Venhuizen\,\textit{et al.} proposed a method classification method to distinguish between \gls{amd} and normal \gls{sdoct} volumes using \gls{bow} models~\cite{Venhuizen2015}.
%
% Method description
The method detects and selects a set of keypoints at each individual B-scan.
Essentially, keeping the salient points comprised at the top $3\%$ of the vertical gradient values.
Then, a texton of size $9 \times 9$ pixels is extracted around each keypoint, and \gls{pca} is applied to reduce the dimension of every texton to get a feature vector of size $9$.
All extracted feature vectors are used to create a codebook using \textit{k}-means clustering.
Then, each \gls{oct} volume is represented in terms of this codebook and is characterized as a histogram that captures the codebook occurrences.
These histograms are used as feature vector to train a \gls{rf} with a maximum of $100$ trees.
%
% Reported results
The method is tested using a publicly available dataset of $384$ \gls{oct} volumes~\cite{VENHUIZEN_DATASET}, achieving an \gls{auc} of $0.984$.

%%% Venhuizen2015
%
% Brief method description (or goal)
Srinivasan\,\textit{et~al.}~\cite{Srinivasan2014} proposed a classification method to distinguish \gls{dme}, \gls{amd} and normal \gls{sdoct} volumes.
%
% Method description
The \gls{oct} images pre-processed by first enhancing sparsity in a transform-domain (BM3D~\cite{dabov2007image}), to reduce their speckle noise, and then by flattening the retinal curvature to reduce the inter-patient variations.
\gls{hog} features are then extracted from multi-resolution pyramid of each pre-processed slice of a volume.
These features are classified using a linear \gls{svm}.
Note that the method classifies each individual B-scan into one of three categories, i.e.\gls{dme}, \gls{amd}, and normal, and then classifies a volume based on the number of B-scans in each category.
%
% Reported results
The method is also tested using a publicly available of $45$ patients equally subdivided into the three aforementioned classes, this method leads to a correct classification rate of $100 \%$, $100 \%$ and $86.67 \%$ for normal, \gls{dme} and \gls{amd} patients, respectively.
\todo{is this the TP?}
% The images that have been used in their paper, are publicly available but are already preprocessed (i.e., denoised), have different sizes for the \gls{oct} volumes, do not offer a huge variability in term of \gls{dme} lesions, and some of them, without specifying which, have been excluded for the training phase; all these reasons prevent us from using this dataset to benchmark our work.

Replicating the method proposed by Srinivasan \textit{et~al.}~\cite{Srinivasan2014} and adding \gls{pca} to the feature extraction step, as was proposed by Venhuizen \textit{et al.}~\cite{Venhuizen2015}, we also compare the performance of extracted \gls{hog} and \gls{lbp} features (similar to \cite{Srinivasan2014}, features are extracted from multi-resolution pyramid) for classification of B-scans, and accordingly volumes.
{\color{red}This work was submitted for publication to a recent conference.}



Liu\,\textit{et al.} proposed a methodology for detecting macular pathology in \gls{oct} images using \gls{lbp} and gradient information as attributes~\cite{Liu2011}.
The method starts by aligning and flattening the images and creating a $3$-level multi-scale spatial pyramid.
The edge and \gls{lbp} histograms are then extracted from each block of every level of the pyramid.
%is created and edge and \gls{lbp} histograms are extracted in each block at every level of the pyramid.
All the obtained histograms are concatenated into a global descriptor whose dimensions are reduced using \gls{pca}.
Finally a \gls{svm} with an \gls{rbf} kernel is used as classifier.
The method achieved good results in detection \gls{oct} scan containing different pathology such as \gls{dme} or \gls{amd}, with an \gls{auc} of $0.93$ using a dataset of $326$ \gls{oct} scans.


The proposed method by Lemaitre~\emph{et~al.}~\cite{Lemaintre2015miccaiOCT} is based on \gls{lbp} features to describe the texture of \gls{oct} images and dictionary learning using the \gls{bow} models~\cite{Sivic2003}.
Our later study proposes a standard classification procedure to differentiate between \gls{dme} and normal \gls{sdoct} volumes~\cite{Lemaitre2015}The data is pre-processed using \gls{nlm} filtering.
The volumes are mapped into discrete set of structures namely: local, when these structures correspond to patches; or global, when the structures correspond to volume slices or the whole volume.
These structures are described in terms of texture using \gls{lbp} or \gls{lbptop} and encoded using histogram, \gls{pca} or \gls{bow} to produce a single feature vector in order to present the volumes to a \gls{rf} classifeir.
This methodology was tested against Venhuizen\,\textit{et al.}~\cite{Venhuizen2015} using public and non-public datasets showing an improvement within the results achieving a \gls{se} of 87.5\% and a \gls{sp} of 75\%.



% \input{content/survey/Survey-Table.tex}
